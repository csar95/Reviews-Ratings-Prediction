{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c6e5cf-49ac-4f95-85ed-1d7382e02974",
   "metadata": {
    "id": "b6c6e5cf-49ac-4f95-85ed-1d7382e02974",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from datasets import load_from_disk\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c6d2f9d-9736-418e-9cc3-388ef0f56856",
   "metadata": {
    "id": "3c6d2f9d-9736-418e-9cc3-388ef0f56856",
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00848cbe-d1c5-4df7-8ed7-883d9a4a2c20",
   "metadata": {
    "id": "00848cbe-d1c5-4df7-8ed7-883d9a4a2c20"
   },
   "source": [
    "# Fine-tuning a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65c46af-a162-4544-8e8d-90486ea20334",
   "metadata": {
    "id": "b65c46af-a162-4544-8e8d-90486ea20334",
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d20769b-276b-4532-aee9-ee0388e259e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d20769b-276b-4532-aee9-ee0388e259e8",
    "outputId": "96d4e05c-d84f-46d9-edc8-657414260a3c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.58 s, sys: 508 ms, total: 2.09 s\n",
      "Wall time: 3.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb87f6a-fdfb-4acd-a642-e70c5dcd6152",
   "metadata": {
    "id": "2bb87f6a-fdfb-4acd-a642-e70c5dcd6152"
   },
   "source": [
    "This warning appears because BERT has not been pretrained on classifying pairs of sentences, so the head of the pretrained model has been discarded and a new head suitable for sequence classification has been added instead. The warnings indicate that some weights were not used (the ones corresponding to the dropped pretraining head) and that some others were randomly initialized (the ones for the new head)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5643da-1d95-452f-ac02-609244a7b521",
   "metadata": {
    "id": "fe5643da-1d95-452f-ac02-609244a7b521"
   },
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22c4ab6-a115-413d-b768-ec7ae4c66110",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f22c4ab6-a115-413d-b768-ec7ae4c66110",
    "outputId": "e2931e00-6eda-41c5-93e4-0382016fd8a3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 2688\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 672\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_datasets = load_from_disk(\"ratings_dataset\")\n",
    "preprocessed_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19dc2f1-7a0d-4e52-ae22-8fcf314c5c3c",
   "metadata": {
    "id": "a19dc2f1-7a0d-4e52-ae22-8fcf314c5c3c"
   },
   "source": [
    "The `Dataset.map()` method takes a batched argument that, if set to True, causes it to send a batch of examples to the map function at once (the batch size is configurable but defaults to 1,000). This will be essential to unlock the speed of the “fast” tokenizers.\n",
    "\n",
    "When we specify `batched=True` the function receives a dictionary with the fields of the dataset, but each value is now a list of values, and not just a single value.\n",
    "\n",
    "The function that is responsible for putting together samples inside a batch is called a collate function. It’s an argument you can pass when you build a DataLoader, the default being a function that will just convert your samples to PyTorch tensors and concatenate them (recursively if your elements are lists, tuples, or dictionaries). This won’t be possible in our case since the inputs we have won’t all be of the same size. We only apply padding as necessary on each batch and avoid having over-long inputs with a lot of padding. This will speed up training by quite a bit.\n",
    "\n",
    "`padding=\"longest\"` pads the sequences up to the maximum sequence length. Padding makes sure all our sentences have the same length by adding a special word/token to the sentences with fewer values.\n",
    "\n",
    "`truncation=True` will truncate the sequences that are longer than the model max length. With Transformer models, there is a limit to the lengths of the sequences we can pass the models. Most models handle sequences of up to 512 or 1024 tokens, and will crash when asked to process longer sequences. One solution is to truncate the sequences.\n",
    "\n",
    "The tokenizer object can handle the conversion to specific framework tensors, which can then be directly sent to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbdbaf57-ba3d-4793-86b9-9c616f8c228e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbdbaf57-ba3d-4793-86b9-9c616f8c228e",
    "outputId": "db5b674e-ce93-4b52-effa-609e2e17d2e9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /content/ratings_dataset/train/cache-ea9568559a366c79.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /content/ratings_dataset/validation/cache-d972a06c06777879.arrow\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(review):\n",
    "    return tokenizer(review[\"text\"], truncation=True)  # padding=\"longest\"\n",
    "\n",
    "tokenized_datasets = preprocessed_datasets.map(tokenize_function, batched=True, batch_size=512)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b84c4f9-7f56-431b-9c52-a8bbd1a41639",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b84c4f9-7f56-431b-9c52-a8bbd1a41639",
    "outputId": "de361894-ae37-4838-d546-68b167178a81",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2688\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 672\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4fab8e-9cf0-4c0b-8699-8f954296f432",
   "metadata": {
    "id": "af4fab8e-9cf0-4c0b-8699-8f954296f432",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training with the Trainer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "349ad583-493c-4303-8769-84a6281b7bf9",
   "metadata": {
    "id": "349ad583-493c-4303-8769-84a6281b7bf9"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ffb854-22af-4a66-a224-84e6ddb13a4b",
   "metadata": {
    "id": "66ffb854-22af-4a66-a224-84e6ddb13a4b",
    "tags": []
   },
   "source": [
    "The first step before we can define our Trainer is to define a TrainingArguments class that will contain all the hyperparameters the Trainer will use for training and evaluation. The only argument you have to provide is a directory where the trained model will be saved, as well as the checkpoints along the way. For all the rest, you can leave the defaults, which should work pretty well for a basic fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f26058b-ffdb-4a20-b352-fa500d7d4d59",
   "metadata": {
    "id": "7f26058b-ffdb-4a20-b352-fa500d7d4d59",
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"models/bert-trainer\",\n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  num_train_epochs=N_EPOCHS,\n",
    "                                  per_device_train_batch_size=BATCH_SIZE,\n",
    "                                  per_device_eval_batch_size=BATCH_SIZE,\n",
    "                                  learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df370544-31ad-40f6-9cde-6e577c67091b",
   "metadata": {
    "id": "df370544-31ad-40f6-9cde-6e577c67091b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    results = {}\n",
    "    results.update(accuracy_metric.compute(predictions=preds, references=labels))\n",
    "    results.update(f1_metric.compute(predictions=preds, references=labels, average=\"weighted\"))\n",
    "    results.update(recall_metric.compute(predictions=preds, references=labels, average=\"weighted\"))\n",
    "    results.update(precision_metric.compute(predictions=preds, references=labels, average=\"weighted\"))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6903e4d-9369-4a31-8e64-eb139a17b52a",
   "metadata": {
    "id": "a6903e4d-9369-4a31-8e64-eb139a17b52a"
   },
   "source": [
    "When we pass the tokenizer, the default data_collator used by the Trainer will be a `DataCollatorWithPadding` as defined previously, so we can skip the line `data_collator=data_collator` in this call.\n",
    "- ¿Sigue siendo necesario inicializar data_collator o tampoco?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de270a90-ce0a-48ac-8ef6-037cc49673d9",
   "metadata": {
    "id": "de270a90-ce0a-48ac-8ef6-037cc49673d9"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model, training_args,\n",
    "                  train_dataset=tokenized_datasets[\"train\"],\n",
    "                  eval_dataset=tokenized_datasets[\"validation\"],\n",
    "                  data_collator=data_collator,\n",
    "                  tokenizer=tokenizer,\n",
    "                  compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe17897-07b0-4359-8b34-dfd844ab0190",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "bbe17897-07b0-4359-8b34-dfd844ab0190",
    "outputId": "f348bbcc-84bd-490d-85d7-d972a247d974"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1680' max='1680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1680/1680 06:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.093178</td>\n",
       "      <td>0.525298</td>\n",
       "      <td>0.521761</td>\n",
       "      <td>0.525298</td>\n",
       "      <td>0.557235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.175100</td>\n",
       "      <td>1.153612</td>\n",
       "      <td>0.534226</td>\n",
       "      <td>0.526796</td>\n",
       "      <td>0.534226</td>\n",
       "      <td>0.555456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.699700</td>\n",
       "      <td>1.329214</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.548635</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.568604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.699700</td>\n",
       "      <td>1.659811</td>\n",
       "      <td>0.544643</td>\n",
       "      <td>0.550359</td>\n",
       "      <td>0.544643</td>\n",
       "      <td>0.572937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.243400</td>\n",
       "      <td>1.971264</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.558719</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.576341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1680, training_loss=0.6402489457811628, metrics={'train_runtime': 379.4533, 'train_samples_per_second': 35.419, 'train_steps_per_second': 4.427, 'total_flos': 860120874051888.0, 'train_loss': 0.6402489457811628, 'epoch': 5.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76b7cf4-8aef-4ecf-a530-2fdddffcee69",
   "metadata": {
    "id": "e76b7cf4-8aef-4ecf-a530-2fdddffcee69"
   },
   "source": [
    "## Training with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11bfabfe-c6cd-44ec-bb4b-f8c656735f47",
   "metadata": {
    "id": "11bfabfe-c6cd-44ec-bb4b-f8c656735f47",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d97410e4-a51f-46d9-a564-ffa89f110ab1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d97410e4-a51f-46d9-a564-ffa89f110ab1",
    "outputId": "31a6a65d-274d-4db5-8213-6459dd1001c6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c4a3e-49c5-445e-ad8f-15d285067598",
   "metadata": {
    "id": "530c4a3e-49c5-445e-ad8f-15d285067598"
   },
   "source": [
    "- Remove the columns corresponding to values the model does not expect (`text`).\n",
    "- Set the format of the datasets so they return PyTorch tensors instead of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03231bb7-32f2-43a2-8c29-7e7152b4cf88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03231bb7-32f2-43a2-8c29-7e7152b4cf88",
    "outputId": "cb23f5b5-cbf6-440d-a123-b441878d9863",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2688\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 672\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns(['text'])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5394a51-5d6d-48c3-a3ae-ff99f2083c1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5394a51-5d6d-48c3-a3ae-ff99f2083c1b",
    "outputId": "943fd0a3-8811-4ab1-e49f-c826be5b301d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7fe5661b27f0>,\n",
       " 'validation': <torch.utils.data.dataloader.DataLoader at 0x7fe5661b22b0>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(tokenized_datasets[\"validation\"], batch_size=BATCH_SIZE, collate_fn=data_collator)\n",
    "\n",
    "dataLoaders = {\n",
    "    'train': train_dataloader,\n",
    "    'validation': eval_dataloader\n",
    "}\n",
    "\n",
    "dataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8267a1ce-40c3-4a56-9022-37d0a0bd5e19",
   "metadata": {
    "id": "8267a1ce-40c3-4a56-9022-37d0a0bd5e19"
   },
   "source": [
    "To quickly check there is no mistake in the data processing, we can inspect a batch like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cac1c3-23a9-4a28-b92c-c0f79cc7f2cd",
   "metadata": {
    "id": "c5cac1c3-23a9-4a28-b92c-c0f79cc7f2cd",
    "outputId": "b5df4aa2-673c-4d7b-d5d3-8b43c94612b2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 112]),\n",
       " 'token_type_ids': torch.Size([8, 112]),\n",
       " 'attention_mask': torch.Size([8, 112]),\n",
       " 'labels': torch.Size([8])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16f803-d7aa-47a7-988f-bad78b168dda",
   "metadata": {
    "id": "1c16f803-d7aa-47a7-988f-bad78b168dda"
   },
   "source": [
    "The actual shapes will vary since we set `shuffle=True` for the training dataloader and we are padding to the maximum length inside the batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16976872-9603-4033-87bf-542b73087116",
   "metadata": {
    "id": "16976872-9603-4033-87bf-542b73087116"
   },
   "source": [
    "To make sure that everything will go smoothly during training, we pass our batch to this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c4ecc-2e4b-4201-b7bf-056817fb7edf",
   "metadata": {
    "id": "f22c4ecc-2e4b-4201-b7bf-056817fb7edf",
    "outputId": "8b96f24b-c193-49a2-dfdc-6ce8eb21fe44",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8351, grad_fn=<NllLossBackward0>) torch.Size([8, 5])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**batch)\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc0aef-b1dd-4c1d-9a8d-469a105c73e9",
   "metadata": {
    "id": "07fc0aef-b1dd-4c1d-9a8d-469a105c73e9"
   },
   "source": [
    "The learning rate scheduler used by default is just a linear decay from the maximum value (5e-5) to 0. To properly define it, we need to know the number of training steps we will take, which is the number of epochs we want to run multiplied by the number of training batches (which is the length of our training dataloader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b4691db-8e62-483a-819f-117ed99cf009",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b4691db-8e62-483a-819f-117ed99cf009",
    "outputId": "b14a2b25-10f7-489c-af3d-3fdd9987410b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1680\n"
     ]
    }
   ],
   "source": [
    "num_training_steps = N_EPOCHS * len(train_dataloader)\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cdf5c84-17be-48fc-a8fc-73d6e218286c",
   "metadata": {
    "id": "3cdf5c84-17be-48fc-a8fc-73d6e218286c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78738088-92c2-4ca4-98e2-f6598df560f4",
   "metadata": {
    "id": "78738088-92c2-4ca4-98e2-f6598df560f4"
   },
   "source": [
    "### The training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-E_NKUmFQ-NC",
   "metadata": {
    "id": "-E_NKUmFQ-NC"
   },
   "source": [
    "#### Manual metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89564584-efd1-4101-bd96-b0118fed721b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "d3bd4987aaeb4817953a0683d68affdc",
      "5bd67e959bcf40dd9fb80273902749dc",
      "3e72214d55da4c11bb4c70b1a5fb6729",
      "d3927172e0814f658e88743de54a5cfd",
      "78fcfa1b6da842fa810a6f574400bb53",
      "3482d96e28ea451caca6393208f3d14f",
      "81e4ad90fcdc4b8fb49a641379a6c536",
      "7b7e381e43d844369d317c982be0610e",
      "ec928976a831485d9940e3b9a939ab95",
      "1820613d7e3a44c5a0acca6b9a944e00",
      "0ab089a1abf7456f8c58f49749021490"
     ]
    },
    "id": "89564584-efd1-4101-bd96-b0118fed721b",
    "outputId": "6ff1f22a-e73d-43ed-e68c-a27575a00093",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bd4987aaeb4817953a0683d68affdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73f6cbb3-59cf-49f4-b75c-59614087d1a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "id": "73f6cbb3-59cf-49f4-b75c-59614087d1a6",
    "outputId": "7c78bb6f-d4cc-47fd-88fd-f922207cca7d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | loss: 1.333 - accuracy: 0.3925 - val_loss: 1.126 - val_accuracy: 0.4985\n",
      "Epoch 2/5 | loss: 0.963 - accuracy: 0.5893 - val_loss: 1.059 - val_accuracy: 0.5387\n",
      "Epoch 3/5 | loss: 0.6274 - accuracy: 0.7407 - val_loss: 1.22 - val_accuracy: 0.5432\n",
      "Epoch 4/5 | loss: 0.3001 - accuracy: 0.8955 - val_loss: 1.505 - val_accuracy: 0.5699\n",
      "Epoch 5/5 | loss: 0.1178 - accuracy: 0.9702 - val_loss: 1.71 - val_accuracy: 0.5536\n"
     ]
    }
   ],
   "source": [
    "patience = 7  # Number of epochs with no improvement after which training will be stopped\n",
    "early_stopping = False\n",
    "best_loss = float('inf')\n",
    "epochs_with_no_improvement = 0\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    epoch_results = {}\n",
    "\n",
    "    for phase in [\"train\", \"validation\"]:\n",
    "        # This sets the execution mode and informs layers (e.g., Dropout, BatchNorm) designed to behave differently during training and evaluation\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        correct_in_dataset = 0\n",
    "        \n",
    "        # For each batch update model parameters / weights\n",
    "        for batch in dataLoaders[phase]:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            optimizer.zero_grad()               # Sets the gradients of all optimized tensors to zero. Same as model.zero_grad() if all model parameters are in the optimizer\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss            \n",
    "            \n",
    "            if phase == \"train\":\n",
    "                loss.backward()                 # Computes the gradient of loss w.r.t all the parameters in loss that have requires_grad=True and store them in x.grad (x.grad += dloss/dx)\n",
    "                optimizer.step()                # Performs a single optimization step (parameter update based on the gradients)\n",
    "                lr_scheduler.step()\n",
    "                progress_bar.update(1)\n",
    "            \n",
    "            running_loss += loss.item()            \n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            \n",
    "            correct_in_dataset += (predictions == batch['labels']).sum().item()\n",
    "        \n",
    "        if phase == \"train\":\n",
    "            epoch_results['train_loss'] = running_loss/len(dataLoaders[phase])\n",
    "            epoch_results['train_accuracy'] = correct_in_dataset/len(tokenized_datasets[phase])\n",
    "\n",
    "        else:\n",
    "            epoch_results['val_loss'] = running_loss/len(dataLoaders[phase])\n",
    "            epoch_results['val_accuracy'] = correct_in_dataset/len(tokenized_datasets[phase])\n",
    "            \n",
    "            if epoch_results['val_loss'] < best_loss:\n",
    "                best_loss = epoch_results['val_loss']\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "                epochs_with_no_improvement = 0\n",
    "            else:\n",
    "                epochs_with_no_improvement += 1\n",
    "\n",
    "            if epochs_with_no_improvement == patience:\n",
    "                model.load_state_dict(best_model)\n",
    "                early_stopping = True\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{N_EPOCHS} | loss: {epoch_results['train_loss']:.4} - accuracy: {epoch_results['train_accuracy']:.4} - val_loss: {epoch_results['val_loss']:.4} - val_accuracy: {epoch_results['val_accuracy']:.4}\")\n",
    "\n",
    "    if early_stopping:\n",
    "        print('Early stopping!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FhmWXrzoREez",
   "metadata": {
    "id": "FhmWXrzoREez"
   },
   "source": [
    "#### HuggingFace metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "BLsaUxWXNcip",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "95bd293357f4470a834bc442d18e2d3e",
      "e19366908c9c45f7aaf1b2891c0690dc",
      "84a40cef1ea64e18ba10ca5a40a4d77e",
      "d2da8f4f61b84ba0b2182a91a5a17051",
      "429d82adad134d9db1a0afe22b238f87",
      "b7af596792d549f7bdabc6a7289846ec",
      "3913764a88eb43e0a96e75a2bd0db87f",
      "3e24657a53e649c5bc38b95414f979ea",
      "902d213129fb4ee092e4d99f7a4863b8",
      "9fa8548827e34f068752d7604328afc9",
      "2cbd02a6bffd492e900aefcb94a8b55e"
     ]
    },
    "id": "BLsaUxWXNcip",
    "outputId": "cdbc7ed8-6d0a-4173-f0f2-e12f56468689"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bd293357f4470a834bc442d18e2d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "Q-nQkoKvLN_Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "id": "Q-nQkoKvLN_Z",
    "outputId": "2cc3dda1-393e-456f-f204-d276bc27b399",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | loss: 1.278 - accuracy: 0.4196 - val_loss: 1.108 - val_accuracy: 0.5179\n",
      "Epoch 2/5 | loss: 0.9151 - accuracy: 0.6127 - val_loss: 1.066 - val_accuracy: 0.5372\n",
      "Epoch 3/5 | loss: 0.5985 - accuracy: 0.7708 - val_loss: 1.26 - val_accuracy: 0.5461\n",
      "Epoch 4/5 | loss: 0.3131 - accuracy: 0.8943 - val_loss: 1.547 - val_accuracy: 0.5357\n",
      "Epoch 5/5 | loss: 0.1285 - accuracy: 0.9654 - val_loss: 1.646 - val_accuracy: 0.5461\n"
     ]
    }
   ],
   "source": [
    "patience = 7  # Number of epochs with no improvement after which training will be stopped\n",
    "early_stopping = False\n",
    "best_loss = float('inf')\n",
    "epochs_with_no_improvement = 0\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    metrics = {\n",
    "        'train': {\n",
    "            'accuracy': evaluate.load(\"accuracy\")\n",
    "         },\n",
    "        'validation': {\n",
    "            'accuracy': evaluate.load(\"accuracy\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "    epoch_results = {}\n",
    "\n",
    "    for phase in [\"train\", \"validation\"]:\n",
    "        # This sets the execution mode and informs layers (e.g., Dropout, BatchNorm) designed to behave differently during training and evaluation\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # For each batch update model parameters / weights\n",
    "        for batch in dataLoaders[phase]:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            optimizer.zero_grad()               # Sets the gradients of all optimized tensors to zero. Same as model.zero_grad() if all model parameters are in the optimizer\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss            \n",
    "            \n",
    "            if phase == \"train\":\n",
    "                loss.backward()                 # Computes the gradient of loss w.r.t all the parameters in loss that have requires_grad=True and store them in x.grad (x.grad += dloss/dx)\n",
    "                optimizer.step()                # Performs a single optimization step (parameter update based on the gradients)\n",
    "                lr_scheduler.step()\n",
    "                progress_bar.update(1)\n",
    "\n",
    "            running_loss += loss.item()            \n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            metrics[phase]['accuracy'].add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "        \n",
    "        if phase == \"train\":\n",
    "            epoch_results['train_loss'] = running_loss/len(dataLoaders[phase])\n",
    "            epoch_results['train_accuracy'] = metrics[phase]['accuracy'].compute()['accuracy']\n",
    "\n",
    "        else:\n",
    "            epoch_results['val_loss'] = running_loss/len(dataLoaders[phase])\n",
    "            epoch_results['val_accuracy'] = metrics[phase]['accuracy'].compute()['accuracy']\n",
    "            \n",
    "            if epoch_results['val_loss'] < best_loss:\n",
    "                best_loss = epoch_results['val_loss']\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "                epochs_with_no_improvement = 0\n",
    "            else:\n",
    "                epochs_with_no_improvement += 1\n",
    "\n",
    "            if epochs_with_no_improvement == patience:\n",
    "                model.load_state_dict(best_model)\n",
    "                early_stopping = True\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{N_EPOCHS} | loss: {epoch_results['train_loss']:.4} - accuracy: {epoch_results['train_accuracy']:.4} - val_loss: {epoch_results['val_loss']:.4} - val_accuracy: {epoch_results['val_accuracy']:.4}\")\n",
    "\n",
    "    if early_stopping:\n",
    "        print('Early stopping!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WG5p49TvNdnR",
   "metadata": {
    "id": "WG5p49TvNdnR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0ab089a1abf7456f8c58f49749021490": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1820613d7e3a44c5a0acca6b9a944e00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cbd02a6bffd492e900aefcb94a8b55e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3482d96e28ea451caca6393208f3d14f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3913764a88eb43e0a96e75a2bd0db87f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e24657a53e649c5bc38b95414f979ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e72214d55da4c11bb4c70b1a5fb6729": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b7e381e43d844369d317c982be0610e",
      "max": 1680,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec928976a831485d9940e3b9a939ab95",
      "value": 1680
     }
    },
    "429d82adad134d9db1a0afe22b238f87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bd67e959bcf40dd9fb80273902749dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3482d96e28ea451caca6393208f3d14f",
      "placeholder": "​",
      "style": "IPY_MODEL_81e4ad90fcdc4b8fb49a641379a6c536",
      "value": "100%"
     }
    },
    "78fcfa1b6da842fa810a6f574400bb53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b7e381e43d844369d317c982be0610e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81e4ad90fcdc4b8fb49a641379a6c536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84a40cef1ea64e18ba10ca5a40a4d77e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e24657a53e649c5bc38b95414f979ea",
      "max": 1680,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_902d213129fb4ee092e4d99f7a4863b8",
      "value": 1680
     }
    },
    "902d213129fb4ee092e4d99f7a4863b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "95bd293357f4470a834bc442d18e2d3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e19366908c9c45f7aaf1b2891c0690dc",
       "IPY_MODEL_84a40cef1ea64e18ba10ca5a40a4d77e",
       "IPY_MODEL_d2da8f4f61b84ba0b2182a91a5a17051"
      ],
      "layout": "IPY_MODEL_429d82adad134d9db1a0afe22b238f87"
     }
    },
    "9fa8548827e34f068752d7604328afc9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7af596792d549f7bdabc6a7289846ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2da8f4f61b84ba0b2182a91a5a17051": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fa8548827e34f068752d7604328afc9",
      "placeholder": "​",
      "style": "IPY_MODEL_2cbd02a6bffd492e900aefcb94a8b55e",
      "value": " 1680/1680 [06:21&lt;00:00,  5.19it/s]"
     }
    },
    "d3927172e0814f658e88743de54a5cfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1820613d7e3a44c5a0acca6b9a944e00",
      "placeholder": "​",
      "style": "IPY_MODEL_0ab089a1abf7456f8c58f49749021490",
      "value": " 1680/1680 [06:10&lt;00:00,  6.48it/s]"
     }
    },
    "d3bd4987aaeb4817953a0683d68affdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5bd67e959bcf40dd9fb80273902749dc",
       "IPY_MODEL_3e72214d55da4c11bb4c70b1a5fb6729",
       "IPY_MODEL_d3927172e0814f658e88743de54a5cfd"
      ],
      "layout": "IPY_MODEL_78fcfa1b6da842fa810a6f574400bb53"
     }
    },
    "e19366908c9c45f7aaf1b2891c0690dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7af596792d549f7bdabc6a7289846ec",
      "placeholder": "​",
      "style": "IPY_MODEL_3913764a88eb43e0a96e75a2bd0db87f",
      "value": "100%"
     }
    },
    "ec928976a831485d9940e3b9a939ab95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
